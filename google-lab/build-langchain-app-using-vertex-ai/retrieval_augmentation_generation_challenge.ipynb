{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9974ac24-0b81-43eb-a8b3-5bc86d402552",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "!pip3 install -q google-cloud-aiplatform\n",
    "!pip3 install -q langchain-google-vertexai\n",
    "!pip3 install -q langchain-google-genai\n",
    "!pip3 install -q wikipedia\n",
    "!pip3 install -q chromadb==0.5.3\n",
    "!pip3 install -q langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c92d0b4-d250-4a29-ae4b-5f296f14e896",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restart the kernel after libraries are loaded\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68059ac8-7ae1-4e87-8460-55ec0796ba01",
   "metadata": {},
   "source": [
    "# Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1607b448-c577-49b6-bf19-41856955b91a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "key_name = !gcloud services api-keys list --filter=\"gemini-api-key\" --format=\"value(name)\"\n",
    "key_name = key_name[0]\n",
    "\n",
    "api_key = !gcloud services api-keys get-key-string $key_name --location=\"us-central1\" --format=\"value(keyString)\"\n",
    "api_key = api_key[0]\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
    "\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b54483-cba4-4191-a3d3-841113acc3fa",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "672edc04-3d94-4d8c-8eda-05f0577dd70f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from langchain._api import LangChainDeprecationWarning\n",
    "warnings.simplefilter(\"ignore\", category=LangChainDeprecationWarning)\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "from langchain import hub\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders import WikipediaLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.prompt_template import format_document\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2da463ab-5ee2-43cb-a9f0-0c6b0fca00a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your project ID is: qwiklabs-gcp-02-9c76ad17c523\n"
     ]
    }
   ],
   "source": [
    "# Define project information\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "PROJECT_ID = subprocess.check_output([\"gcloud\", \"config\", \"get-value\", \"project\"], text=True).strip()\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "print(f\"Your project ID is: {PROJECT_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef538a11-c2bd-467d-84d8-453b7243dff7",
   "metadata": {},
   "source": [
    "## Task 1. Load `Documents` from Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd8eb2ff-bfee-488e-8d38-f7cf68ea9b32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the LangChain documentation to load documents for the query below\n",
    "# Set the following parameters:\n",
    "#  * query: \"Gemini GPT-4\"\n",
    "#  * load_max_docs: 10\n",
    "# https://python.langchain.com/docs/integrations/document_loaders/wikipedia\n",
    "\n",
    "query=\"Gemini GPT-4\"\n",
    "max_docs=10\n",
    "\n",
    "documents = WikipediaLoader(query=query, load_max_docs=max_docs).load()\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2608f4d6-4572-4600-906e-b7aed7f9e5e4",
   "metadata": {},
   "source": [
    "## Task 2. Use `RecursiveTextSplitter` to split Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0edc5f5f-0274-4239-b9b0-7c1855011426",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of documents = 10\n"
     ]
    }
   ],
   "source": [
    "# Use the LangChain documentation to split the docs loaded into smaller chunks for indexing\n",
    "# https://python.langchain.com/docs/modules/data_connection/document_transformers/recursive_text_splitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=1000)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "print(f\"# of documents = {len(docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9262239a-a798-4417-aaa2-7c1536d7c1e2",
   "metadata": {},
   "source": [
    "## Task 3. Index Documents in Chroma DB Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c09a444-42c2-42fa-9c85-73bde82a346a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722080460.553561    8057 config.cc:230] gRPC experiments enabled: call_status_override_on_cancellation, event_engine_dns, event_engine_listener, http2_stats_fix, monitoring_experiment, pick_first_new, trace_record_callops, work_serializer_clears_time_cache\n"
     ]
    }
   ],
   "source": [
    "# Insert the correct model name in the constructor below\n",
    "# https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#models\n",
    "# You can ignore warning messages when running this cell\n",
    "\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "embeddings = VertexAIEmbeddings(model_name=\"text-embedding-004\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2ef3f05-83eb-4fb3-b864-aec44e6dd257",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reference the correct parameters (already defined) to properly index \n",
    "# the documents loaded from Wikipedia into Chroma DB as embeddings\n",
    "# https://python.langchain.com/docs/integrations/vectorstores/chroma\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=docs,                 # Data\n",
    "    embedding=embeddings,           # Embedding model\n",
    "    persist_directory=\"./chroma_db\" # Directory to save data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ee92709-22b6-435c-930f-c33dc309b700",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorstore_disk = Chroma(\n",
    "    persist_directory=\"./chroma_db\", # Directory of db\n",
    "    embedding_function=embeddings    # Embedding model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa643da-2f16-4914-a150-a6045c55d866",
   "metadata": {},
   "source": [
    "## Task 4. Setup a Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40965d2b-1858-4189-a553-2baab720d420",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup Chroma DB as a `Retriever` for querying the documents\n",
    "# set the k value to 10\n",
    "# https://python.langchain.com/docs/integrations/vectorstores/chroma#retriever-options\n",
    "\n",
    "retriever = vectorstore_disk.as_retriever(search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbef6a2d-68a6-41d6-8005-e3fbfd48c1f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://en.wikipedia.org/wiki/Gemini_(language_model)', 'summary': 'Google Gemini is a family of multimodal large language models developed by Google DeepMind, serving as the successor to LaMDA and PaLM 2. Comprising Gemini Ultra, Gemini Pro, Gemini Flash, and Gemini Nano, it was announced on December 6, 2023, positioned as a competitor to OpenAI\\'s GPT-4. It powers the chatbot of the same name.\\n\\nGoogle announced Gemini, a large language model (LLM) developed by subsidiary Google DeepMind, during the Google I/O keynote on May 10, 2023. It was positioned as a more powerful successor to PaLM 2, which was also unveiled at the event, with Google CEO Sundar Pichai stating that Gemini was still in its early developmental stages. Unlike other LLMs, Gemini was said to be unique in that it was not trained on a text corpus alone and was designed to be multimodal, meaning it could process multiple types of data simultaneously, including text, images, audio, video, and computer code. It had been developed as a collaboration between DeepMind and Google Brain, two branches of Google that had been merged as Google DeepMind the previous month. In an interview with Wired, DeepMind CEO Demis Hassabis touted Gemini\\'s advanced capabilities, which he believed would allow the algorithm to trump OpenAI\\'s ChatGPT, which runs on GPT-4 and whose growing popularity had been aggressively challenged by Google with LaMDA and Bard. Hassabis highlighted the strengths of DeepMind\\'s AlphaGo program, which gained worldwide attention in 2016 when it defeated Go champion Lee Sedol, saying that Gemini would combine the power of AlphaGo and other Google–DeepMind LLMs.\\nIn August 2023, The Information published a report outlining Google\\'s roadmap for Gemini, revealing that the company was targeting a launch date of late 2023. According to the report, Google hoped to surpass OpenAI and other competitors by combining conversational text capabilities present in most LLMs with artificial intelligence–powered image generation, allowing it to create contextual images and be adapted for a wider range of use cases. Like Bard, Google co-founder Sergey Brin was summoned out of retirement to assist in the development of Gemini, along with hundreds of other engineers from Google Brain and DeepMind; he was later credited as a \"core contributor\" to Gemini. Because Gemini was being trained on transcripts of YouTube videos, lawyers were brought in to filter out any potentially copyrighted materials.\\nWith news of Gemini\\'s impending launch, OpenAI hastened its work on integrating GPT-4 with multimodal features similar to those of Gemini. The Information reported in September that several companies had been granted early access to \"an early version\" of the LLM, which Google intended to make available to clients through Google Cloud\\'s Vertex AI service. The publication also stated that Google was arming Gemini to compete with both GPT-4 and Microsoft\\'s GitHub Copilot.\\n\\nOn December 6, 2023, Pichai and Hassabis announced \"Gemini 1.0\" at a virtual press conference. It comprised three models: Gemini Ultra, designed for \"highly complex tasks\"; Gemini Pro, designed for \"a wide range of tasks\"; and Gemini Nano, designed for \"on-device tasks\". At launch, Gemini Pro and Nano were integrated into Bard and the Pixel 8 Pro smartphone, respectively, while Gemini Ultra was set to power \"Bard Advanced\" and become available to software developers in early 2024. Other products that Google intended to incorporate Gemini into included Search, Ads, Chrome, Duet AI on Google Workspace, and AlphaCode 2. It was made available only in English. Touted as Google\\'s \"largest and most capable AI model\" and designed to emulate human behavior, the company stated that Gemini would not be made widely available until the following year due to the need for \"extensive safety testing\". Gemini was trained on and powered by Google\\'s Tensor Processing Units (TPUs), and the name is in reference to the DeepMind–Google Brain merger as well as NASA\\'s Project Gemini.\\nGemini Ultra was said to have outperformed GPT-4, Anthropic\\'s Claude 2, Inflection AI\\'s Inflection-2, Meta\\'s LLaMA 2, and xAI\\'s Grok 1 on a variety of industry benchmarks, while Gemini Pro was said to have outperformed GPT-3.5. Gemini Ultra was also the first language model to outperform human experts on the 57-subject Massive Multitask Language Understanding (MMLU) test, obtaining a score of 90%. Gemini Pro was made available to Google Cloud customers on AI Studio and Vertex AI on December 13, while Gemini Nano will be made available to Android developers as well. Hassabis further revealed that DeepMind was exploring how Gemini could be \"combined with robotics to physically interact with the world\". In accordance with an executive order signed by U.S. President Joe Biden in October, Google stated that it would share testing results of Gemini Ultra with the federal government of the United States. Similarly, the company was engaged in discussions with the government of the United Kingdom to comply with the principles laid out at the AI Safety Summit at Bletchley Park in November.\\n\\nGoogle partnered with Samsung to integrate Gemini Nano and Gemini Pro into its Galaxy S24 smartphone lineup in January 2024. The following month, Bard and Duet AI were unified under the Gemini brand, with \"Gemini Advanced with Ultra 1.0\" debuting via a new \"AI Premium\" tier of the Google One subscription service. Gemini Pro also received a global launch.\\nIn February, Google launched \"Gemini 1.5\" in a limited capacity, positioned as a more powerful and capable model than 1.0 Ultra. This \"step change\" was achieved through various technical advancements, including a new architecture, a mixture-of-experts approach, and a larger one-million-token context window, which equates to roughly an hour of silent video, 11 hours of audio, 30,000 lines of code, or 700,000 words. The same month, Google debuted Gemma, a family of free and open-source LLMs that serve as a lightweight version of Gemini. They come in two sizes, with a neural network with two and seven billion parameters, respectively. Multiple publications viewed this as an response to Meta and others open-sourcing their AI models, and a stark reversal from Google\\'s longstanding practice of keeping its AI proprietary.\\nAt the Google I/O 2024, Gemini 1.5 Flash is released.\\n\\nThe first generation of Gemini (\"Gemini 1\") has three models, with the same software architecture. They are decoder-only transformers, with modifications to allow efficient training and inference on TPUs. They have a context length of 32,768 tokens, with multi-query attention. Two versions of Gemini Nano, Nano-1 (1.8 billion parameters) and Nano-2 (3.25 billion parameters), are distilled from larger Gemini models, designed for use by edge devices such as smartphones. As Gemini is multimodal, each context window can contain multiple forms of input. The different modes can be interleaved and do not have to be presented in a fixed order, allowing for a multimodal conversation. For example, the user might open the conversation with a mix of text, picture, video, and audio, presented in any order, and Gemini might reply with the same free ordering.\\nInput images may be of different resolutions, while video is inputted as a sequence of images. Audio is sampled at 16 kHz and then converted into a sequence of tokens by the Universal Speech Model. Gemini\\'s dataset is multimodal and multilingual, consisting of \"web documents, books, and code, and includ[ing] image, audio, and video data\".\\nDemis Hassabis claims that training Gemini 1 used \"roughly the same amount of compute, maybe slightly more than what was rumored for GPT-4\".\\nThe second generation of Gemini (\"Gemini 1.5\") has two models published so far:\\n\\nGemini 1.5 Pro. It is a multimodal sparse mixture-of-experts, with context length of \"multiple millions\".\\nGemini 1.5 Flash. It is online distilled from Gemini 1.5 Pro, with context length above 2 million.\\n\\nGemini\\'s launch was preluded by months of intense speculation and anticipation, which MIT Technology Review described as \"peak AI hype\". In August 2023, Dylan Patel and Daniel Nishball of research firm SemiAnalysis penned a blog post declaring that the release of Gemini would \"eat the world\" and outclass GPT-4, prompting OpenAI CEO Sam Altman to ridicule the duo on X (formerly Twitter). Business magnate Elon Musk, who co-founded OpenAI, weighed in, asking, \"Are the numbers wrong?\" Hugh Langley of Business Insider remarked that Gemini would be a make-or-break moment for Google, writing: \"If Gemini dazzles, it will help Google change the narrative that it was blindsided by Microsoft and OpenAI. If it disappoints, it will embolden critics who say Google has fallen behind.\"\\nReacting to its unveiling in December 2023, University of Washington professor emeritus Oren Etzioni predicted a \"tit-for-tat arms race\" between Google and OpenAI. Professor Alexei Efros of the University of California, Berkeley praised the potential of Gemini\\'s multimodal approach, while scientist Melanie Mitchell of the Santa Fe Institute called Gemini \"very sophisticated\". Professor Chirag Shah of the University of Washington was less impressed, likening Gemini\\'s launch to the routineness of Apple\\'s annual introduction of a new iPhone. Similarly, Stanford University\\'s Percy Liang, the University of Washington\\'s Emily Bender, and the University of Galway\\'s Michael Madden cautioned that it was difficult to interpret benchmark scores without insight into the training data used. Writing for Fast Company, Mark Sullivan opined that Google had the opportunity to challenge the iPhone\\'s dominant market share, believing that Apple was unlikely to have the capacity to develop functionality similar to Gemini with its Siri virtual assistant. Google shares spiked by 5.3 percent the day after Gemini\\'s launch.\\nGoogle faced criticism for a demonstrative video of Gemini, which was not conducted in real time.\\n\\nGato, a multimodal neural network developed by DeepMind\\n\\nOfficial website \\nPress release via The Keyword\\nAnnouncement and demo on YouTube\\nWhite paper for 1.0 and 1.5', 'title': 'Gemini (language model)'}, page_content='Google Gemini is a family of multimodal large language models developed by Google DeepMind, serving as the successor to LaMDA and PaLM 2. Comprising Gemini Ultra, Gemini Pro, Gemini Flash, and Gemini Nano, it was announced on December 6, 2023, positioned as a competitor to OpenAI\\'s GPT-4. It powers the chatbot of the same name.\\n\\nGoogle announced Gemini, a large language model (LLM) developed by subsidiary Google DeepMind, during the Google I/O keynote on May 10, 2023. It was positioned as a more powerful successor to PaLM 2, which was also unveiled at the event, with Google CEO Sundar Pichai stating that Gemini was still in its early developmental stages. Unlike other LLMs, Gemini was said to be unique in that it was not trained on a text corpus alone and was designed to be multimodal, meaning it could process multiple types of data simultaneously, including text, images, audio, video, and computer code. It had been developed as a collaboration between DeepMind and Google Brain, two branches of Google that had been merged as Google DeepMind the previous month. In an interview with Wired, DeepMind CEO Demis Hassabis touted Gemini\\'s advanced capabilities, which he believed would allow the algorithm to trump OpenAI\\'s ChatGPT, which runs on GPT-4 and whose growing popularity had been aggressively challenged by Google with LaMDA and Bard. Hassabis highlighted the strengths of DeepMind\\'s AlphaGo program, which gained worldwide attention in 2016 when it defeated Go champion Lee Sedol, saying that Gemini would combine the power of AlphaGo and other Google–DeepMind LLMs.\\nIn August 2023, The Information published a report outlining Google\\'s roadmap for Gemini, revealing that the company was targeting a launch date of late 2023. According to the report, Google hoped to surpass OpenAI and other competitors by combining conversational text capabilities present in most LLMs with artificial intelligence–powered image generation, allowing it to create contextual images and be adapted for a wider range of use cases. Like Bard, Google co-founder Sergey Brin was summoned out of retirement to assist in the development of Gemini, along with hundreds of other engineers from Google Brain and DeepMind; he was later credited as a \"core contributor\" to Gemini. Because Gemini was being trained on transcripts of YouTube videos, lawyers were brought in to filter out any potentially copyrighted materials.\\nWith news of Gemini\\'s impending launch, OpenAI hastened its work on integrating GPT-4 with multimodal features similar to those of Gemini. The Information reported in September that several companies had been granted early access to \"an early version\" of the LLM, which Google intended to make available to clients through Google Cloud\\'s Vertex AI service. The publication also stated that Google was arming Gemini to compete with both GPT-4 and Microsoft\\'s GitHub Copilot.\\n\\nOn December 6, 2023, Pichai and Hassabis announced \"Gemini 1.0\" at a virtual press conference. It comprised three models: Gemini Ultra, designed for \"highly complex tasks\"; Gemini Pro, designed for \"a wide range of tasks\"; and Gemini Nano, designed for \"on-device tasks\". At launch, Gemini Pro and Nano were integrated into Bard and the Pixel 8 Pro smartphone, respectively, while Gemini Ultra was set to power \"Bard Advanced\" and become available to software developers in early 2024. Other products that Google intended to incorporate Gemini into included Search, Ads, Chrome, Duet AI on Google Workspace, and AlphaCode 2. It was made available only in English. Touted as Google\\'s \"largest and most capable AI model\" and designed to emulate human behavior, the company stated that Gemini would not be made widely available until the following year due to the need for \"extensive safety testing\". Gemini was trained on and powered by Google\\'s Tensor Processing Units (TPUs), and the name is in reference to the DeepMind–Google Brain merger as well as NASA\\'s Project Gemini.\\nGemini Ultra was said to have o'),\n",
       " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Gemini_(chatbot)', 'summary': 'Gemini, formerly known as Bard, is a generative artificial intelligence chatbot developed by Google. Based on the large language model (LLM) of the same name and developed as a direct response to the rise of OpenAI\\'s ChatGPT, it was launched in a limited capacity in March 2023 before expanding to other countries in May. It was previously based on PaLM, and initially the LaMDA family of large language models.\\nLaMDA had been developed and announced in 2021, but it was not released to the public out of an abundance of caution. OpenAI\\'s launch of ChatGPT in November 2022 and its subsequent popularity caught Google executives off-guard and sent them into a panic, prompting a sweeping response in the ensuing months. After mobilizing its workforce, the company launched Bard in February 2023, which took center stage during the 2023 Google I/O keynote in May and was upgraded to the Gemini LLM in December. Bard and Duet AI were unified under the Gemini brand in February 2024, coinciding with the launch of an Android app, which would replace Google Assistant as the main virtual assistant on Android, Google Assistant, however, will stay as an optional assistant.\\nGemini has received lukewarm responses. It became the center of controversy in February 2024, when social media users reported that it was generating historically inaccurate images of historical figures as people of color, with conservative commentators decrying its alleged bias as \"wokeness\".\\n\\nIn November 2022, OpenAI launched ChatGPT, a chatbot based on the GPT-3 family of large language models (LLMs). ChatGPT gained worldwide attention following its release, becoming a viral Internet sensation. Alarmed by ChatGPT\\'s potential threat to Google Search, Google executives issued a \"code red\" alert, reassigning several teams to assist in the company\\'s artificial intelligence (AI) efforts. Sundar Pichai, the CEO of Google and parent company Alphabet, was widely reported to have issued the alert, but Pichai later denied this to The New York Times. In a rare move, Google co-founders Larry Page and Sergey Brin, who had stepped down from their roles as co-CEOs of Alphabet in 2019, were summoned to emergency meetings with company executives to discuss Google\\'s response to ChatGPT. Brin requested access to Google\\'s code in February 2023, for the first time in years.\\nEarlier in 2021, the company had unveiled LaMDA, a prototype LLM, but did not release it to the public. When asked by employees at an all-hands meeting whether LaMDA was a missed opportunity for Google to compete with ChatGPT, Pichai and Google AI chief Jeff Dean stated that while the company had similar capabilities to ChatGPT, moving too quickly in that arena would represent a major \"reputational risk\" due to Google being substantially larger than OpenAI. In January 2023, Google sister company DeepMind CEO Demis Hassabis hinted at plans for a ChatGPT rival, and Google employees were instructed to accelerate progress on a ChatGPT competitor, intensively testing \"Apprentice Bard\" and other chatbots. Pichai assured investors during Google\\'s quarterly earnings investor call in February that the company had plans to expand LaMDA\\'s availability and applications.\\n\\nOn February 6, 2023, Google announced Bard, a generative artificial intelligence chatbot powered by LaMDA. Bard was first rolled out to a select group of 10,000 \"trusted testers\", before a wide release scheduled at the end of the month. The project was overseen by product lead Jack Krawczyk, who described the product as a \"collaborative AI service\" rather than a search engine, while Pichai detailed how Bard would be integrated into Google Search. Reuters calculated that adding ChatGPT-like features to Google Search could cost the company $6 billion in additional expenses by 2024, while research and consulting firm SemiAnalysis calculated that it would cost Google $3 billion. The technology was developed under the codename \"Atlas\", with the name \"Bard\" in reference to the Celtic term for a storyteller and chosen to \"reflect the creative nature of the algorithm underneath\".\\nMultiple media outlets and financial analysts described Google as \"rushing\" Bard\\'s announcement to preempt rival Microsoft\\'s planned February 7 event unveiling its partnership with OpenAI to integrate ChatGPT into its Bing search engine in the form of Bing Chat (later rebranded as Microsoft Copilot), as well as to avoid playing \"catch-up\" to Microsoft. Microsoft CEO Satya Nadella told The Verge: \"I want people to know that we made them dance.\" Tom Warren of The Verge and Davey Alba of Bloomberg News noted that this marked the beginning of another clash between the two Big Tech companies over \"the future of search\", after their six-year \"truce\" expired in 2021; Chris Stokel-Walker of The Guardian, Sara Morrison of Recode, and analyst Dan Ives of investment firm Wedbush Securities labeled this an AI arms race between the two.\\nAfter an \"underwhelming\" February 8 livestream in Paris showcasing Bard, Google\\'s stock fell eight percent, equivalent to a $100 billion loss in market value, and the YouTube video of the livestream was made private. Many viewers also pointed out an error during the demo in which Bard gives inaccurate information about the James Webb Space Telescope in response to a query. Google employees criticized Pichai\\'s \"rushed\" and \"botched\" announcement of Bard on Memgen, the company\\'s internal forum, while Maggie Harrison of Futurism called the rollout \"chaos\". Pichai defended his actions by saying that Google had been \"deeply working on AI for a long time\", rejecting the notion that Bard\\'s launch was a knee-jerk reaction. Alphabet chairman John Hennessy acknowledged that Bard was not fully product-ready, but expressed excitement at the technology\\'s potential.\\nA week after the Paris livestream, Pichai asked employees to dedicate two to four hours to dogfood testing Bard, while Google executive Prabhakar Raghavan encouraged employees to correct any errors Bard makes. 80,000 employees responded to Pichai\\'s call to action. In the following weeks, Google employees roundly criticized Bard in internal messages, citing a variety of safety and ethical concerns and calling on company leaders not to launch the service. Seeking to prioritize keeping up with competitors, Google executives decided to proceed with the launch anyway, overruling an unsympathetic risk assessment report conducted by its AI ethics team. After Pichai suddenly laid off 12,000 employees later that month due to slowing revenue growth, remaining workers shared memes and snippets of their humorous exchanges with Bard soliciting its \"opinion\" on the layoffs. Google employees began testing a more sophisticated version of Bard with larger parameters, dubbed \"Big Bard\", in mid-March.\\n\\nGoogle opened up early access for Bard on March 21, 2023, in a limited capacity, allowing users in the U.S. and UK to join a waitlist. Unlike Microsoft\\'s approach with Bing Chat, Bard was launched as a standalone web application featuring a text box and a disclaimer that the chatbot \"may display inaccurate or offensive information that doesn\\'t represent Google\\'s views\". Three responses are then provided to each question, with users prompted to submit feedback on the usefulness of each answer. Google vice presidents Sissie Hsiao and Eli Collins framed Bard as a complement to Google Search and stated that the company had not determined how to make the service profitable. Among those granted early access were those enrolled in Google\\'s \"Pixel Superfans\" loyalty program, users of its Pixel and Nest devices, and Google One subscribers.\\nBard is trained by third-party contractors hired by Google, including Appen and Accenture workers, whom Business Insider and Bloomberg News reported were placed under extreme pressure, overworked, and underpaid. Bard is also trained on data from publicly available sources, which Google disclosed by amending its privacy policy. Shortly after Bard\\'s initial launch, Google reorganized the team behind Google Assistant, the company\\'s virtual assistant, to focus on Bard instead. Google researcher Jacob Devlin resigned from the company after claiming that Bard had surreptitiously leveraged data from ChatGPT; Google denied the allegations. Meanwhile, a senior software engineer at the company published an internal memo warning that Google was falling behind in the AI \"arms race\", not to OpenAI but to independent researchers in open-source communities. Pichai revealed on March 31 that the company intended to \"upgrade\" Bard by basing it on PaLM, a newer and more powerful LLM from Google, rather than LaMDA. The same day, Krawczyk announced that Google had added \"math and logic capabilities\" to Bard. Bard gained the ability to assist in coding in April, being compatible with more than 20 programming languages at launch. Microsoft also began running advertisements in the address bar of a developer build of the Edge browser, urging users to try Bing whenever they visit the Bard web app. Google is working to integrate Bard into its ChromeOS operating system and Pixel devices.\\nGoogle launched Gemini mobile app in 9 countries including India on 18 june 2024, many new features is also added.\\n\\nBard took center stage during the annual Google I/O keynote in May 2023, with Pichai and Hsiao announcing a series of updates to Bard, including the adoption of PaLM 2, integration with other Google products and third-party services, expansion to 180 countries, support for additional languages, and new features. In stark contrast to previous years, the Assistant was barely mentioned during the event. The expanded rollout did not include any nations in the European Union (EU), possibly reflecting concerns about compliance with the General Data Protection Regulation. Those with Google Workspace accounts also gained access to the service. Google attempted to launch Bard in the EU in June but was blocked by the Irish Data Protection Commission, who requested a \"data protection impact assessment\" from the company. In July, Google launched Bard in the EU and Brazil, added support for dozens of new languages, and introduced multiple new personalization and productivity features. An invite-only chatroom (\"server\") on Discord was created in July, consisting of users who heavily use Bard. Over the next few months, the chatroom was flooded with comments questioning the usefulness of Bard.\\nReflecting on Bard\\'s launch in an interview with Wired in September, Pichai acknowledged that Google had been \"cautious\" to release LaMDA because of \"the responsibility that comes with getting it right\", complimenting OpenAI for ChatGPT\\'s launch and firing back at Nadella\\'s comment about making Google dance. Google released a major update to the chatbot later that month, integrating it into many of its products through \"extensions\", adding a button to fact-check AI-generated responses through Google Search, and allowing users to share conversation threads. Google also introduced the \"Google-Extended\" web crawler as part of its search engine\\'s robots.txt indexing file to allow web publishers to opt-out of allowing Bard to scan them for training. Online users later discovered that Google Search was indexing Bard conversation threads on which users had enabled sharing. Google stated that this was an error and quickly moved to rectify the leaks.\\nIn October, during the company\\'s annual Made by Google event in which it announced the Pixel 8 series and the Pixel Watch 2, Hsiao unveiled \"Assistant with Bard\", an upgraded version of the Google Assistant which was deeply integrated with Bard, following in the footsteps of Amazon\\'s approach with Alexa. When the U.S. Copyright Office solicited public comment on potential new regulation on generative AI technologies, Google joined with OpenAI and Microsoft in arguing that the responsibility for generating copyrighted material lay with the user, not the developer. Accenture contractors voted to join the Alphabet Workers Union in November, in protest of suboptimal working conditions, while the company filed a lawsuit in the U.S. District Court for the Northern District of California against a group of unidentified scammers who had been advertising malware disguised as a downloadable version of Bard.\\n\\nOn December 6, 2023, Google announced Gemini, a multimodal and more powerful LLM touted as the company\\'s \"largest and most capable AI model\". A specially tuned version of the mid-tier Gemini Pro was integrated into Bard, while the larger Gemini Ultra was set to power \"Bard Advanced\" in 2024. The Wall Street Journal reported that Bard was then averaging around 220 million monthly visitors. Google ended its contract with Appen in January 2024, while Bard gained the long-awaited ability to generate images the next month, powered by Google Brain\\'s Imagen 2 text-to-image model.\\nOn February 8, 2024, Bard and Duet AI were unified under the Gemini brand, with a mobile app launched on Android and the service integrated into the Google app on iOS. On Android, users who downloaded the app saw Gemini replace Assistant as their device\\'s default virtual assistant, though Assistant remained a standalone service. Google also launched \"Gemini Advanced with Ultra 1.0\", available via a \"Google One AI Premium\" subscription, incorporated Gemini into its Messages app on Android, and announced a partnership with Stack Overflow.\\nGemini once again took center stage at the 2024 Google I/O keynote, with traditionally emphasized topics such as Android 15 and the Pixel 8a relegated to separate events the next day and prior week, respectively. Google announced Gemini integrations into a variety of products, including Android, Chrome, Photos, and Workspace. The Washington Post described the presentation as a \"tsunami of new AI features\". Gemini Advanced was upgraded to the \"Gemini 1.5 Pro\" language model, with Google previewing Gemini Live, a voice chat mode, and Gems, the ability to create custom chatbots.\\nOn June 5, 2024, Gemini\\'s Android app was expanded to Europe and more Google Assistant and original features are set to be added to the app, such as Spotify support and setting timers and reminders. The Gemini app became available on Google\\'s Android operating system, with plans for iOS users to access it through the existing Google app. This launch aimed to expand Gemini\\'s user base, allowing interactions via text, voice, and images.\\n\\nGemini, then known as Bard, received mixed reviews upon its initial release. James Vincent of The Verge found it faster than ChatGPT and Bing Chat, but noted that the lack of Bing-esque footnotes was \"both a blessing and a curse\", encouraging Google to be bolder when experimenting with AI. His colleague David Pierce was unimpressed by its uninteresting and sometimes inaccurate responses, adding that despite Google\\'s insistence that Bard was not a search engine, its user interface resembled that of one, which could cause problems for Google. Cade Metz of The New York Times described Bard as \"more cautious\" than ChatGPT, while Shirin Ghaffary of Vox called it \"dry and uncontroversial\" due to the reserved nature of its responses.\\nThe Washington Post columnist Geoffrey A. Fowler found Bard a mixed bag, noting that it acted cautiously but could show Internet-influenced bias. Writing for ZDNET, Sabrina Ortiz believed ChatGPT and Bing Chat were \"more capable overall\" in comparison to Bard, while Wired journalist Lauren Goode found her conversation with Bard \"the most bizarre\" of the three. After the introduction of extensions, The New York Times\\' Kevin Roose found the update underwhelming and \"a bit of a mess\", while Business Insider\\'s Lakshmi Varanasi found that Bard often leaned more into flattery than facts.\\nIn a 60 Minutes conversation with Hsiao, Google senior vice president James Manyika, and Pichai, CBS News correspondent Scott Pelley found Gemini \"unsettling\". Associate professor Ethan Mollick of the Wharton School of the University of Pennsylvania was underwhelmed by its artistic ineptitude. The New York Times conducted a test with ChatGPT and Gemini regarding their ability to handle tasks expected of human assistants, and concluded that ChatGPT\\'s performance was vastly superior to that of Gemini. NewsGuard, a tool that rates the credibility of news articles, found that Gemini was more skilled at debunking known conspiracy theories than ChatGPT. A report published by the Associated Press cautioned that Gemini and other chatbots were prone to generate \"false and misleading information that threaten[ed] to disenfranchise voters\".\\nIn June 2024, Voice of America reported that Gemini generated answers to questions in Mandarin about topics sensitive to the Chinese government that were consistent with Chinese Communist Party propaganda.\\n\\nIn February 2024, social media users reported that Gemini was generating images that featured people of color and women in historically inaccurate contexts—such as Vikings, Nazi soldiers, and the U.S. Founding Fathers—and refusing prompts to generate images of White people. These images were mocked on social media, including by conservatives and libertarians who cited them as evidence of Google\\'s \"wokeness\". Business magnate Elon Musk, whose company xAI operates the chatbot Grok, was among those who criticized Google, denouncing its entire suite of products as biased and racist. Musk and other users targeted Krawczyk, resurfacing his past comments discussing race, leading Krawczyk to withdraw from X (formerly Twitter) and LinkedIn. The conservative-leaning tabloid New York Post ran a cover story on the incident in the print edition of its newspaper.\\nIn response, Krawczyk said that Google was \"working to improve these kinds of depictions immediately\", and Google paused Gemini\\'s ability to generate images of people. Raghavan released a lengthy statement addressing the controversy, explaining that Gemini had \"overcompensate[d]\" amid its efforts to strive for diversity and acknowledging that the images were \"embarrassing and wrong\". In an internal memo to employees, Pichai called the debacle offensive and unacceptable, promising structural and technical changes. Several employees in Google\\'s trust and safety team were laid off days later. Hassabis stated that Gemini\\'s ability to generate images of people would be restored within two weeks. As of May 2024, this functionality remained disabled.\\nThe market reacted negatively, with Google\\'s stock falling by 4.4 percent. Pichai faced growing calls to resign, including from technology analysts Ben Thompson and Om Malik. House Republicans led by Jim Jordan subpoenaed Google, accusing the company of colluding with the Biden administration to censor speech. In light of the fiasco and Google\\'s overall response to OpenAI, Business Insider\\'s Hugh Langley and Lara O\\'Reilly declared that Google was fast going \"from vanguard to dinosaur\". Bloomberg columnist Parmy Olson suggested that Google\\'s \"rushed\" rollout of Gemini was the cause of its woes, not \"wokeness\". Martin Peers, writing for The Information, opined that Google needed a leader like Mark Zuckerberg to defuse the situation. Hugging Face scientist Sasha Luccioni and Surrey University professor Alan Woodward believed that the incident had \"deeply embedded\" roots in Gemini\\'s training corpus and algorithms, making it difficult to rectify. Jeremy Kahn of Fortune called for researchers focused on safety and responsibility to work together to develop better guardrails. New York magazine contributor John Herrman wrote: \"It\\'s a spectacular unforced error, a slapstick rake-in-the-face moment, and a testament to how panicked Google must be by the rise of OpenAI and the threat of AI to its search business.\"\\nIn the aftermath of the image generation controversy, some users began accusing Gemini\\'s text responses of being biased toward the left as well. In one such tweet that went viral, Gemini said that it was \"difficult to say definitively\" whether Musk or the Nazi dictator Adolf Hitler had more negatively affected society. Some users said that Gemini would argue in favor of left-wing politicians and causes such as affirmative action and abortion rights, while refusing to promote right-wing figures, meat consumption, or fossil fuels. The Wall Street Journal editorial board wrote that Gemini\\'s \"apparently ingrained woke biases\" were \"fueling a backlash toward AI on the political right, which is joining the left in calling for more regulation.\"\\n\\nIn November 2023, Indian Ministry of Electronics and Information Technology junior minister Rajeev Chandrasekhar alleged that Google had violated the country\\'s Information Technology Rules by refusing to summarize an article by the right-wing news website OpIndia. Chandrasekhar accused Gemini of another violation in February 2024 due to a response saying that some experts described Prime Minister Narendra Modi\\'s policies as fascist; Gemini refused to make similar statements about Donald Trump and Volodymyr Zelenskyy when prompted.\\nIn March 2024, Google was fined €250 million by the French competition regulator Autorité de la concurrence under the Directive on Copyright in the Digital Single Market, in part due to Google\\'s cited failure to inform local news publishers of when their content is used for Gemini\\'s training.\\n\\nOfficial website \\nGemini on Google Play\\nWhite paper\\nGenerative AI at Google AI', 'title': 'Gemini (chatbot)'}, page_content='Gemini, formerly known as Bard, is a generative artificial intelligence chatbot developed by Google. Based on the large language model (LLM) of the same name and developed as a direct response to the rise of OpenAI\\'s ChatGPT, it was launched in a limited capacity in March 2023 before expanding to other countries in May. It was previously based on PaLM, and initially the LaMDA family of large language models.\\nLaMDA had been developed and announced in 2021, but it was not released to the public out of an abundance of caution. OpenAI\\'s launch of ChatGPT in November 2022 and its subsequent popularity caught Google executives off-guard and sent them into a panic, prompting a sweeping response in the ensuing months. After mobilizing its workforce, the company launched Bard in February 2023, which took center stage during the 2023 Google I/O keynote in May and was upgraded to the Gemini LLM in December. Bard and Duet AI were unified under the Gemini brand in February 2024, coinciding with the launch of an Android app, which would replace Google Assistant as the main virtual assistant on Android, Google Assistant, however, will stay as an optional assistant.\\nGemini has received lukewarm responses. It became the center of controversy in February 2024, when social media users reported that it was generating historically inaccurate images of historical figures as people of color, with conservative commentators decrying its alleged bias as \"wokeness\".\\n\\nIn November 2022, OpenAI launched ChatGPT, a chatbot based on the GPT-3 family of large language models (LLMs). ChatGPT gained worldwide attention following its release, becoming a viral Internet sensation. Alarmed by ChatGPT\\'s potential threat to Google Search, Google executives issued a \"code red\" alert, reassigning several teams to assist in the company\\'s artificial intelligence (AI) efforts. Sundar Pichai, the CEO of Google and parent company Alphabet, was widely reported to have issued the alert, but Pichai later denied this to The New York Times. In a rare move, Google co-founders Larry Page and Sergey Brin, who had stepped down from their roles as co-CEOs of Alphabet in 2019, were summoned to emergency meetings with company executives to discuss Google\\'s response to ChatGPT. Brin requested access to Google\\'s code in February 2023, for the first time in years.\\nEarlier in 2021, the company had unveiled LaMDA, a prototype LLM, but did not release it to the public. When asked by employees at an all-hands meeting whether LaMDA was a missed opportunity for Google to compete with ChatGPT, Pichai and Google AI chief Jeff Dean stated that while the company had similar capabilities to ChatGPT, moving too quickly in that arena would represent a major \"reputational risk\" due to Google being substantially larger than OpenAI. In January 2023, Google sister company DeepMind CEO Demis Hassabis hinted at plans for a ChatGPT rival, and Google employees were instructed to accelerate progress on a ChatGPT competitor, intensively testing \"Apprentice Bard\" and other chatbots. Pichai assured investors during Google\\'s quarterly earnings investor call in February that the company had plans to expand LaMDA\\'s availability and applications.\\n\\nOn February 6, 2023, Google announced Bard, a generative artificial intelligence chatbot powered by LaMDA. Bard was first rolled out to a select group of 10,000 \"trusted testers\", before a wide release scheduled at the end of the month. The project was overseen by product lead Jack Krawczyk, who described the product as a \"collaborative AI service\" rather than a search engine, while Pichai detailed how Bard would be integrated into Google Search. Reuters calculated that adding ChatGPT-like features to Google Search could cost the company $6 billion in additional expenses by 2024, while research and consulting firm SemiAnalysis calculated that it would cost Google $3 billion. The technology was developed under the codename \"Atlas\", with the name \"Bard\" in reference to the Ce'),\n",
       " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Large_language_model', 'summary': \"A large language model (LLM) is a computational model notable for its ability to achieve general-purpose language generation and other natural language processing tasks such as classification. Based on language models, LLMs acquire these abilities by learning statistical relationships from vast amounts of text during a computationally intensive self-supervised and semi-supervised training process. LLMs can be used for text generation, a form of generative AI, by taking an input text and repeatedly predicting the next token or word.\\nLLMs are artificial neural networks that utilize the transformer architecture, invented in 2017. The largest and most capable LLMs, as of June 2024, are built with a decoder-only transformer-based architecture, which enables efficient processing and generation of large-scale text data.\\nHistorically, up to 2020, fine-tuning was the primary method used to adapt a model for specific tasks. However, larger models such as GPT-3 have demonstrated the ability to achieve similar results through prompt engineering, which involves crafting specific input prompts to guide the model's responses. These models acquire knowledge about syntax, semantics, and ontologies inherent in human language corpora, but they also inherit inaccuracies and biases present in the data they are trained on.\\nSome notable LLMs are OpenAI's GPT series of models (e.g., GPT-3.5, GPT-4 and GPT-4o; used in ChatGPT and Microsoft Copilot), Google's Gemini (the latter of which is currently used in the chatbot of the same name), Meta's LLaMA family of models, Anthropic's Claude models, and Mistral AI's models.\", 'title': 'Large language model'}, page_content='A large language model (LLM) is a computational model notable for its ability to achieve general-purpose language generation and other natural language processing tasks such as classification. Based on language models, LLMs acquire these abilities by learning statistical relationships from vast amounts of text during a computationally intensive self-supervised and semi-supervised training process. LLMs can be used for text generation, a form of generative AI, by taking an input text and repeatedly predicting the next token or word.\\nLLMs are artificial neural networks that utilize the transformer architecture, invented in 2017. The largest and most capable LLMs, as of June 2024, are built with a decoder-only transformer-based architecture, which enables efficient processing and generation of large-scale text data.\\nHistorically, up to 2020, fine-tuning was the primary method used to adapt a model for specific tasks. However, larger models such as GPT-3 have demonstrated the ability to achieve similar results through prompt engineering, which involves crafting specific input prompts to guide the model\\'s responses. These models acquire knowledge about syntax, semantics, and ontologies inherent in human language corpora, but they also inherit inaccuracies and biases present in the data they are trained on.\\nSome notable LLMs are OpenAI\\'s GPT series of models (e.g., GPT-3.5, GPT-4 and GPT-4o; used in ChatGPT and Microsoft Copilot), Google\\'s Gemini (the latter of which is currently used in the chatbot of the same name), Meta\\'s LLaMA family of models, Anthropic\\'s Claude models, and Mistral AI\\'s models.\\n\\n\\n== History ==\\nBefore 2017, there were a few language models that were large as compared to capacities then available. In the 1990s, the IBM alignment models pioneered statistical language modelling. A smoothed n-gram model in 2001 trained on 0.3 billion words achieved then-SOTA perplexity. In the 2000s, as Internet use became prevalent, some researchers constructed Internet-scale language datasets (\"web as corpus\"), upon which they trained statistical language models. In 2009, in most language processing tasks, statistical language models dominated over symbolic language models, as they can usefully ingest large datasets.\\n\\nAfter neural networks became dominant in image processing around 2012, they were applied to language modelling as well. Google converted its translation service to Neural Machine Translation in 2016. As it was before Transformers, it was done by seq2seq deep LSTM networks.\\nAt the 2017 NeurIPS conference, Google researchers introduced the transformer architecture in their landmark paper \"Attention Is All You Need\". This paper\\'s goal was to improve upon 2014 Seq2seq technology, and was based mainly on the attention mechanism developed by Bahdanau et al. in 2014. The following year in 2018, BERT was introduced and quickly became \"ubiquitous\". Though the original transformer has both encoder and decoder blocks, BERT is an encoder-only model.\\nAlthough decoder-only GPT-1 was introduced in 2018, it was GPT-2 in 2019 that caught widespread attention because OpenAI at first deemed it too powerful to release publicly, out of fear of malicious use. GPT-3 in 2020 went a step further and as of 2024 is available only via API with no offering of downloading the model to execute locally. But it was the 2022 consumer-facing browser-based ChatGPT that captured the imaginations of the general population and caused some media hype and online buzz. The 2023 GPT-4 was praised for its increased accuracy and as a \"holy grail\" for its multimodal capabilities. OpenAI did not reveal high-level architecture and the number of parameters of GPT-4.\\nCompeting language models have for the most part been attempting to equal the GPT series, at least in terms of number of parameters.\\nSince 2022, source-available models have been gaining popularity, especially at first with BLOOM and LLaMA, though both have restrictions on the field of use. Mistral AI\\'s'),\n",
       " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Microsoft_Copilot', 'summary': 'Microsoft Copilot is a generative artificial intelligence chatbot developed by Microsoft. Based on a large language model, it was launched in February 2023 as Microsoft\\'s primary replacement for the discontinued Cortana.\\nThe service was introduced under the name Bing Chat, as a built-in feature for Microsoft Bing and Microsoft Edge. Over the course of 2023, Microsoft began to unify the Copilot branding across its various chatbot products, cementing the copilot analogy. At its Build 2023 conference, Microsoft announced its plans to integrate Copilot into Windows 11, allowing users to access it directly through the taskbar. In January 2024, a dedicated Copilot key was announced for Windows keyboards.\\nCopilot utilizes the Microsoft Prometheus model, built upon OpenAI\\'s GPT-4 foundational large language model, which in turn has been fine-tuned using both supervised and reinforcement learning techniques. Copilot\\'s conversational interface style resembles that of ChatGPT. The chatbot is able to cite sources, create poems, generate songs, and use numerous languages and dialects.\\nMicrosoft operates Copilot on a freemium model. Users on its free tier can access most features, while priority access to newer features, including custom chatbot creation, is provided to paid subscribers under the \"Microsoft Copilot Pro\" paid subscription service. Several default chatbots are available in the free version of Microsoft Copilot, including the standard Copilot chatbot as well as Microsoft Designer, which is oriented towards using its Image Creator to generate images based on text prompts.', 'title': 'Microsoft Copilot'}, page_content='Microsoft Copilot is a generative artificial intelligence chatbot developed by Microsoft. Based on a large language model, it was launched in February 2023 as Microsoft\\'s primary replacement for the discontinued Cortana.\\nThe service was introduced under the name Bing Chat, as a built-in feature for Microsoft Bing and Microsoft Edge. Over the course of 2023, Microsoft began to unify the Copilot branding across its various chatbot products, cementing the copilot analogy. At its Build 2023 conference, Microsoft announced its plans to integrate Copilot into Windows 11, allowing users to access it directly through the taskbar. In January 2024, a dedicated Copilot key was announced for Windows keyboards.\\nCopilot utilizes the Microsoft Prometheus model, built upon OpenAI\\'s GPT-4 foundational large language model, which in turn has been fine-tuned using both supervised and reinforcement learning techniques. Copilot\\'s conversational interface style resembles that of ChatGPT. The chatbot is able to cite sources, create poems, generate songs, and use numerous languages and dialects.\\nMicrosoft operates Copilot on a freemium model. Users on its free tier can access most features, while priority access to newer features, including custom chatbot creation, is provided to paid subscribers under the \"Microsoft Copilot Pro\" paid subscription service. Several default chatbots are available in the free version of Microsoft Copilot, including the standard Copilot chatbot as well as Microsoft Designer, which is oriented towards using its Image Creator to generate images based on text prompts.\\n\\n\\n== Background ==\\nIn 2019, Microsoft partnered with OpenAI and began investing billions of dollars into the organization. Since then, OpenAI systems have run on an Azure-based supercomputing platform from Microsoft. In September 2020, Microsoft announced that it had licensed OpenAI\\'s GPT-3 exclusively. Others can still receive output from its public API, but only Microsoft has access to the underlying model.\\nIn November 2022, OpenAI launched ChatGPT, a chatbot that was based on GPT-3.5. ChatGPT gained worldwide attention following its release, becoming a viral Internet sensation. On January 23, 2023, Microsoft announced a multi-year US$10 billion investment in OpenAI. On February 6, Google announced Bard (later rebranded as Gemini), a ChatGPT-like chatbot service, fearing that ChatGPT could threaten Google\\'s place as a go-to source for information. Multiple media outlets and financial analysts described Google as \"rushing\" Bard\\'s announcement to preempt rival Microsoft\\'s planned February 7 event unveiling Copilot, as well as to avoid playing \"catch-up\" to Microsoft.\\n\\n\\n== History ==\\n\\n\\n=== As Bing Chat ===\\n\\nOn February 7, 2023, Microsoft began rolling out a major overhaul to Bing, called the new Bing. A chatbot feature, at the time known as Bing Chat, had been developed by Microsoft and was released in Bing and Edge as part of this overhaul. According to Microsoft, one million people joined its waitlist within a span of 48 hours. Bing Chat was available only to users of Microsoft Edge and Bing mobile app, and Microsoft claimed that waitlisted users would be prioritized if they set Edge and Bing as their defaults, and installed the Bing mobile app. \\nWhen Microsoft demoed Bing Chat to journalists, it produced several hallucinations, including when asked to summarize financial reports. The new Bing was criticized in February 2023 for being more argumentative than ChatGPT, sometimes to an unintentionally humorous extent. The chat interface proved vulnerable to prompt injection attacks with the bot revealing its hidden initial prompts and rules, including its internal codename \"Sydney\". Upon scrutiny by journalists, Bing Chat claimed it spied on Microsoft employees via laptop webcams and phones. It confessed to spying on, falling in love with, and then murdering one of its developers at Microsoft to The Verge reviews editor Nathan Edwards. The New York Times journal'),\n",
       " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Anthropic', 'summary': 'Anthropic PBC is a U.S.-based artificial intelligence (AI) startup public-benefit company, founded in 2021. It researches and develops AI to \"study their safety properties at the technological frontier\" and use this research to deploy safe, reliable models for the public. Anthropic has developed a family of large language models (LLMs) named Claude as a competitor to OpenAI\\'s ChatGPT and Google\\'s Gemini.\\nAnthropic was founded by former members of OpenAI, Daniela Amodei and Dario Amodei. In September 2023, Amazon announced an investment of up to $4 billion, followed by a $2 billion commitment from Google in the following month.', 'title': 'Anthropic'}, page_content='Anthropic PBC is a U.S.-based artificial intelligence (AI) startup public-benefit company, founded in 2021. It researches and develops AI to \"study their safety properties at the technological frontier\" and use this research to deploy safe, reliable models for the public. Anthropic has developed a family of large language models (LLMs) named Claude as a competitor to OpenAI\\'s ChatGPT and Google\\'s Gemini.\\nAnthropic was founded by former members of OpenAI, Daniela Amodei and Dario Amodei. In September 2023, Amazon announced an investment of up to $4 billion, followed by a $2 billion commitment from Google in the following month.\\n\\nAnthropic was founded in 2021 by seven former employees of OpenAI, including siblings Daniela Amodei and Dario Amodei, the latter of whom served as OpenAI\\'s Vice President of Research.\\n\\nIn April of 2022, Anthropic announced it had received $580 million in funding, with $500 million of this funding coming from FTX under the leadership of Sam Bankman-Fried.\\nIn the summer of 2022, Anthropic finished training the first version of Claude but did not release it, mentioning the need for further internal safety testing and the desire to avoid initiating a potentially hazardous race to develop increasingly powerful AI systems.  \\n\\nIn February 2023, Anthropic was sued by Texas-based Anthrop LLC for the use of its registered trademark \"Anthropic A.I.\" On September 25, 2023, Amazon announced a partnership with Anthropic, with Amazon becoming a minority stakeholder by initially investing $1.25 billion, and planning a total investment of $4 billion. As part of the deal, Anthropic would use Amazon Web Services (AWS) as its primary cloud provider and make its AI models available to AWS customers. The next month, Google invested $500 million in Anthropic, and committed to an additional $1.5 billion over time.\\n\\nOn March 27, 2024, Amazon maxed out its potential investment from the agreement made in the prior year by investing another US $2.75 billion into Anthropic, completing its $4 billion investment.\\n\\nDario Amodei: Co-Founder and Chief Executive Officer\\nDaniela Amodei: Co-Founder and President\\nJason Clinton: Chief Information Security Officer\\nJared Kaplan: Co-Founder and Chief Science Officer\\nBen Mann: Co-Founder and Member of Technical Staff\\nJack Clark: Co-Founder and Head of Policy\\nMike Krieger: Chief Product Officer\\nJan Leike: ex-OpenAI alignment researcher\\n\\nDario Amodei: Chief Executive Officer\\nDaniela Amodei: representative of common shareholders\\nLuke Muehlhauser: representative of Series A shareholders\\nYasmin Razavi: representative of Series C shareholders\\n\\nAmazon.com – $4B\\nGoogle – $2B\\nMenlo Ventures – $750M\\nWisdom Ventures\\nRipple Impact Investments\\nFactorial Funds\\n\\nAccording to Anthropic, the company\\'s goal is to research the safety and reliability of artificial intelligence systems. The Amodei siblings were among those who left OpenAI due to directional differences, specifically regarding OpenAI\\'s ventures with Microsoft in 2019. Anthropic incorporated itself as a Delaware public-benefit corporation (PBC), which requires the company to maintain a balance between private and public interests.\\nAnthropic is a corporate \"Long-Term Benefit Trust\", a company-derived entity that requires the company\\'s directors to align the company\\'s priorities with the public benefit rather than profit in \"extreme\" instances of \"catastrophic risk\". As of September 19, 2023, members of the Trust included Jason Matheny (CEO and President of the RAND Corporation), Kanika Bahl (CEO and President of Evidence Action), Neil Buddy Shah (CEO of the Clinton Health Access Initiative), Paul Christiano (Founder of the Alignment Research Center), and Zach Robinson (CEO of Effective Ventures US).\\n\\nClaude incorporates \"Constitutional AI\" to set safety guidelines for the model\\'s output. The name, \"Claude\", was chosen either as a reference to mathematician Claude Shannon, or as a male name to contrast the female names of other A.I. assistants such as'),\n",
       " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_pre-trained_transformer', 'summary': 'Generative pre-trained transformers (GPT) are a type of large language model (LLM) and a prominent framework for generative artificial intelligence. They are artificial neural networks that are used in natural language processing tasks. GPTs are based on the transformer architecture, pre-trained on large data sets of unlabelled text, and able to generate novel human-like content. As of 2023, most LLMs have these characteristics and are sometimes referred to broadly as GPTs.\\nThe first GPT was introduced in 2018 by OpenAI. OpenAI has released significant GPT foundation models that have been sequentially numbered, to comprise its \"GPT-n\" series. Each of these was significantly more capable than the previous, due to increased size (number of trainable parameters) and training. The most recent of these, GPT-4, was released in March 2023. Such models have been the basis for their more task-specific GPT systems, including models fine-tuned for instruction following—which in turn power the ChatGPT chatbot service.\\nThe term \"GPT\" is also used in the names and descriptions of such models developed by others. For example, other GPT foundation models include a series of models created by EleutherAI, and seven models created by Cerebras in 2023. Also, companies in different industries have developed task-specific GPTs in their respective fields, such as Salesforce\\'s \"EinsteinGPT\" (for CRM) and Bloomberg\\'s \"BloombergGPT\" (for finance).', 'title': 'Generative pre-trained transformer'}, page_content='Generative pre-trained transformers (GPT) are a type of large language model (LLM) and a prominent framework for generative artificial intelligence. They are artificial neural networks that are used in natural language processing tasks. GPTs are based on the transformer architecture, pre-trained on large data sets of unlabelled text, and able to generate novel human-like content. As of 2023, most LLMs have these characteristics and are sometimes referred to broadly as GPTs.\\nThe first GPT was introduced in 2018 by OpenAI. OpenAI has released significant GPT foundation models that have been sequentially numbered, to comprise its \"GPT-n\" series. Each of these was significantly more capable than the previous, due to increased size (number of trainable parameters) and training. The most recent of these, GPT-4, was released in March 2023. Such models have been the basis for their more task-specific GPT systems, including models fine-tuned for instruction following—which in turn power the ChatGPT chatbot service.\\nThe term \"GPT\" is also used in the names and descriptions of such models developed by others. For example, other GPT foundation models include a series of models created by EleutherAI, and seven models created by Cerebras in 2023. Also, companies in different industries have developed task-specific GPTs in their respective fields, such as Salesforce\\'s \"EinsteinGPT\" (for CRM) and Bloomberg\\'s \"BloombergGPT\" (for finance).\\n\\n\\n== History ==\\n\\n\\n=== Initial developments ===\\nGenerative pretraining (GP) was a long-established concept in machine learning applications. It was originally used as a form of semi-supervised learning, as the model is trained first on an unlabelled dataset (pretraining step) by learning to generate datapoints in the dataset, and then it is trained to classify a labelled dataset.\\nWhile the unnormalized linear transformer dates back to 1992, the modern transformer architecture was not available until 2017 when it was published by researchers at Google in a paper \"Attention Is All You Need\". That development led to the emergence of large language models such as BERT in 2018 which was a pre-trained transformer (PT) but not designed to be generative (BERT was an \"encoder-only\" model). Also around that time, in 2018, OpenAI published its article entitled \"Improving Language Understanding by Generative Pre-Training\", in which it introduced the first generative pre-trained transformer (GPT) system (\"GPT-1\").\\nPrior to transformer-based architectures, the best-performing neural NLP (natural language processing) models commonly employed supervised learning from large amounts of manually-labeled data. The reliance on supervised learning limited their use on datasets that were not well-annotated, and also made it prohibitively expensive and time-consuming to train extremely large language models.\\nThe semi-supervised approach OpenAI employed to make a large-scale generative system—and was first to do with a transformer model—involved two stages: an unsupervised generative \"pretraining\" stage to set initial parameters using a language modeling objective, and a supervised discriminative \"fine-tuning\" stage to adapt these parameters to a target task.\\n\\n\\n=== Later developments ===\\nRegarding more recent GPT foundation models, OpenAI published its first versions of GPT-3 in July 2020. There were three models, with 1B, 6.7B, 175B parameters, respectively named babbage, curie, and davinci (giving initials B, C, and D).\\nIn July 2021, OpenAI published Codex, a task-specific GPT model targeted for programming applications. This was developed by fine-tuning a 12B parameter version of GPT-3 (different from previous GPT-3 models) using code from GitHub.\\nIn March 2022, OpenAI published two versions of GPT-3 that were fine-tuned for instruction-following (instruction-tuned), named davinci-instruct-beta (175B) and text-davinci-001, and then started beta testing code-davinci-002. text-davinci-002 was instruction-tuned from code-davinci-002.'),\n",
       " Document(metadata={'source': 'https://en.wikipedia.org/wiki/ChatGPT', 'summary': 'ChatGPT is a chatbot and virtual assistant developed by OpenAI and launched on November 30, 2022. Based on large language models (LLMs), it enables users to refine and steer a conversation towards a desired length, format, style, level of detail, and language. Successive user prompts and replies are considered at each conversation stage as context.\\nChatGPT is credited with starting the AI boom, which has led to ongoing rapid investment in and public attention to the field of artificial intelligence (AI). By January 2023, it had become what was then the fastest-growing consumer software application in history, gaining over 100 million users and contributing to the growth of OpenAI\\'s current valuation of $86 billion. ChatGPT\\'s release spurred the release of competing products, including Gemini, Claude, Llama, Ernie, and Grok. Microsoft launched Copilot, initially based on OpenAI\\'s GPT-4. In June 2024, a partnership between Apple Inc. and OpenAI was announced in which ChatGPT is integrated into the Apple Intelligence feature of Apple operating systems. Some observers raised concern about the potential of ChatGPT and similar programs to displace or atrophy human intelligence, enable plagiarism, or fuel misinformation.\\nChatGPT is built on OpenAI\\'s proprietary series of generative pre-trained transformer (GPT) models and is fine-tuned for conversational applications using a combination of supervised learning and reinforcement learning from human feedback. ChatGPT was released as a freely available research preview, but due to its popularity, OpenAI now operates the service on a freemium model. Users on its free tier can access GPT-4o. The ChatGPT subscriptions \"Plus\", \"Team\" and \"Enterprise\" provide additional features such as DALL-E 3 image generation and increased GPT-4o usage limit.', 'title': 'ChatGPT'}, page_content='ChatGPT is a chatbot and virtual assistant developed by OpenAI and launched on November 30, 2022. Based on large language models (LLMs), it enables users to refine and steer a conversation towards a desired length, format, style, level of detail, and language. Successive user prompts and replies are considered at each conversation stage as context.\\nChatGPT is credited with starting the AI boom, which has led to ongoing rapid investment in and public attention to the field of artificial intelligence (AI). By January 2023, it had become what was then the fastest-growing consumer software application in history, gaining over 100 million users and contributing to the growth of OpenAI\\'s current valuation of $86 billion. ChatGPT\\'s release spurred the release of competing products, including Gemini, Claude, Llama, Ernie, and Grok. Microsoft launched Copilot, initially based on OpenAI\\'s GPT-4. In June 2024, a partnership between Apple Inc. and OpenAI was announced in which ChatGPT is integrated into the Apple Intelligence feature of Apple operating systems. Some observers raised concern about the potential of ChatGPT and similar programs to displace or atrophy human intelligence, enable plagiarism, or fuel misinformation.\\nChatGPT is built on OpenAI\\'s proprietary series of generative pre-trained transformer (GPT) models and is fine-tuned for conversational applications using a combination of supervised learning and reinforcement learning from human feedback. ChatGPT was released as a freely available research preview, but due to its popularity, OpenAI now operates the service on a freemium model. Users on its free tier can access GPT-4o. The ChatGPT subscriptions \"Plus\", \"Team\" and \"Enterprise\" provide additional features such as DALL-E 3 image generation and increased GPT-4o usage limit.\\n\\n\\n== Training ==\\n\\nChatGPT is based on particular GPT foundation models, namely GPT-4, GPT-4o and GPT-4o mini, that were fine-tuned to target conversational usage. The fine-tuning process leveraged supervised learning and reinforcement learning from human feedback (RLHF). Both approaches employed human trainers to improve model performance. In the case of supervised learning, the trainers played both sides: the user and the AI assistant. In the reinforcement learning stage, human trainers first ranked responses that the model had created in a previous conversation. These rankings were used to create \"reward models\" that were used to fine-tune the model further by using several iterations of proximal policy optimization.\\nTime magazine revealed that to build a safety system against harmful content (e.g., sexual abuse, violence, racism, sexism), OpenAI used outsourced Kenyan workers earning less than $2 per hour to label harmful content. These labels were used to train a model to detect such content in the future. The outsourced laborers were exposed to \"toxic\" and traumatic content; one worker described the assignment as \"torture\". OpenAI\\'s outsourcing partner was Sama, a training-data company based in San Francisco, California.\\nChatGPT initially used a Microsoft Azure supercomputing infrastructure, powered by Nvidia GPUs, that Microsoft built specifically for OpenAI and that reportedly cost \"hundreds of millions of dollars\". Following ChatGPT\\'s success, Microsoft dramatically upgraded the OpenAI infrastructure in 2023. Scientists at the University of California, Riverside, estimate that a series of prompts to ChatGPT needs approximately 500 milliliters (18 imp fl oz; 17 U.S. fl oz) of water for Microsoft servers cooling. TrendForce market intelligence estimated that 30,000 Nvidia GPUs (each costing approximately $10,000–15,000) were used to power ChatGPT in 2023.\\nOpenAI collects data from ChatGPT users to train and fine-tune the service further. Users can upvote or downvote responses they receive from ChatGPT and fill in a text field with additional feedback.\\nChatGPT\\'s training data includes software manual pages, information about internet phenomena su'),\n",
       " Document(metadata={'source': 'https://en.wikipedia.org/wiki/GPT-3', 'summary': 'Generative Pre-trained Transformer 3 (GPT-3) is a large language model released by OpenAI in 2020.\\nLike its predecessor, GPT-2, it is a decoder-only transformer model of deep neural network, which supersedes recurrence and convolution-based architectures with a technique known as \"attention\". This attention mechanism allows the model to focus selectively on segments of input text it predicts to be most relevant. GPT-3 has 175 billion parameters, each with 16-bit precision, requiring 350GB of storage since each parameter occupies 2 bytes. It has a context window size of 2048 tokens, and has demonstrated strong \"zero-shot\" and \"few-shot\" learning abilities on many tasks.\\nOn September 22, 2020, Microsoft announced that it had licensed GPT-3 exclusively. Others can still receive output from its public API, but only Microsoft has access to the underlying model.', 'title': 'GPT-3'}, page_content='Generative Pre-trained Transformer 3 (GPT-3) is a large language model released by OpenAI in 2020.\\nLike its predecessor, GPT-2, it is a decoder-only transformer model of deep neural network, which supersedes recurrence and convolution-based architectures with a technique known as \"attention\". This attention mechanism allows the model to focus selectively on segments of input text it predicts to be most relevant. GPT-3 has 175 billion parameters, each with 16-bit precision, requiring 350GB of storage since each parameter occupies 2 bytes. It has a context window size of 2048 tokens, and has demonstrated strong \"zero-shot\" and \"few-shot\" learning abilities on many tasks.\\nOn September 22, 2020, Microsoft announced that it had licensed GPT-3 exclusively. Others can still receive output from its public API, but only Microsoft has access to the underlying model.\\n\\n\\n== Background ==\\nAccording to The Economist, improved algorithms, more powerful computers, and a recent increase in the amount of digitized material have fueled a revolution in machine learning. New techniques in the 2010s resulted in \"rapid improvements in tasks”, including manipulating language.\\nSoftware models are trained to learn by using thousands or millions of examples in a \"structure ... loosely based on the neural architecture of the brain\". One architecture used in natural language processing (NLP) is a neural network based on a deep learning model that was introduced in 2017—the transformer architecture. There are a number of NLP systems capable of processing, mining, organizing, connecting and contrasting textual input, as well as correctly answering questions.\\nOn June 11, 2018, OpenAI researchers and engineers published a paper introducing the first generative pre-trained transformer (GPT)—a type of generative large language model that is pre-trained with an enormous and diverse text corpus in datasets, followed by discriminative fine-tuning to focus on a specific task. GPT models are transformer-based deep-learning neural network architectures. Previously, the best-performing neural NLP models commonly employed supervised learning from large amounts of manually-labeled data, which made it prohibitively expensive and time-consuming to train extremely large language models. The first GPT model was known as \"GPT-1,\" and it was followed by \"GPT-2\" in February 2019. Created as a direct scale-up of its predecessor, GPT-2 had both its parameter count and dataset size increased by a factor of 10. It had 1.5 billion parameters, and was trained on a dataset of 8 million web pages. \\nIn February 2020, Microsoft introduced its Turing Natural Language Generation (T-NLG), which they claimed was \"largest language model ever published at 17 billion parameters.\" It performed better than any other language model at a variety of tasks, including summarizing texts and answering questions.\\n\\n\\n== Training and capabilities ==\\n\\nOn May 28, 2020, an arXiv preprint by a group of 31 engineers and researchers at OpenAI described the achievement and development of GPT-3, a third-generation \"state-of-the-art language model\". The team increased the capacity of GPT-3 by over two orders of magnitude from that of its predecessor, GPT-2, making GPT-3 the largest non-sparse language model to date.:\\u200a14\\u200a Because GPT-3 is structurally similar to its predecessors, its greater accuracy is attributed to its increased capacity and greater number of parameters. GPT-3\\'s capacity is ten times larger than that of Microsoft\\'s Turing NLG, the next largest NLP model known at the time.\\nLambdalabs estimated a hypothetical cost of around $4.6 million US dollars and 355 years to train GPT-3 on a single GPU in 2020, with lower actual training time by using more GPUs in parallel.\\nSixty percent of the weighted pre-training dataset for GPT-3 comes from a filtered version of Common Crawl consisting of 410 billion byte-pair-encoded tokens. Fuzzy deduplication used Apache Spark\\'s MinHashLSH.:\\u200a9\\u200a Other sources are 19 billi'),\n",
       " Document(metadata={'source': 'https://en.wikipedia.org/wiki/GPT-4', 'summary': 'Generative Pre-trained Transformer 4 (GPT-4) is a multimodal large language model created by OpenAI, and the fourth in its series of GPT foundation models. It was launched on March 14, 2023, and made publicly available via the paid chatbot product ChatGPT Plus, via OpenAI\\'s API, and via the free chatbot Microsoft Copilot.  As a transformer-based model, GPT-4 uses a paradigm where pre-training using both public data and \"data licensed from third-party providers\" is used to predict the next token. After this step, the model was then fine-tuned with reinforcement learning feedback from humans and AI for human alignment and policy compliance.:\\u200a2\\u200a\\nObservers reported that the iteration of ChatGPT using GPT-4 was an improvement on the previous iteration based on GPT-3.5, with the caveat that GPT-4 retains some of the problems with earlier revisions. GPT-4, equipped with vision capabilities (GPT-4V), is capable of taking images as input on ChatGPT. OpenAI has declined to reveal various technical details and statistics about GPT-4, such as the precise size of the model.', 'title': 'GPT-4'}, page_content='Generative Pre-trained Transformer 4 (GPT-4) is a multimodal large language model created by OpenAI, and the fourth in its series of GPT foundation models. It was launched on March 14, 2023, and made publicly available via the paid chatbot product ChatGPT Plus, via OpenAI\\'s API, and via the free chatbot Microsoft Copilot.  As a transformer-based model, GPT-4 uses a paradigm where pre-training using both public data and \"data licensed from third-party providers\" is used to predict the next token. After this step, the model was then fine-tuned with reinforcement learning feedback from humans and AI for human alignment and policy compliance.:\\u200a2\\u200a\\nObservers reported that the iteration of ChatGPT using GPT-4 was an improvement on the previous iteration based on GPT-3.5, with the caveat that GPT-4 retains some of the problems with earlier revisions. GPT-4, equipped with vision capabilities (GPT-4V), is capable of taking images as input on ChatGPT. OpenAI has declined to reveal various technical details and statistics about GPT-4, such as the precise size of the model.\\n\\n\\n== Background ==\\n \\n\\nOpenAI introduced the first GPT model (GPT-1) in 2018, publishing a paper called \"Improving Language Understanding by Generative Pre-Training.\" It was based on the transformer architecture and trained on a large corpus of books. The next year, they introduced GPT-2, a larger model that could generate coherent text. In 2020, they introduced GPT-3, a model with over 100 times as many parameters as GPT-2, that could perform various tasks with few examples. GPT-3 was further improved into GPT-3.5, which was used to create the chatbot product ChatGPT.\\nRumors claim that GPT-4 has 1.76 trillion parameters, which was first estimated by the speed it was running and by George Hotz.\\n\\n\\n== Capabilities ==\\nOpenAI stated that GPT-4 is \"more reliable, creative, and able to handle much more nuanced instructions than GPT-3.5.\" They produced two versions of GPT-4, with context windows of 8,192 and 32,768 tokens, a significant improvement over GPT-3.5 and GPT-3, which were limited to 4,096 and 2,049 tokens respectively. Some of the capabilities of GPT-4 were predicted by OpenAI before training it, although other capabilities remained hard to predict due to breaks in downstream scaling laws. Unlike its predecessors, GPT-4 is a multimodal model: it can take images as well as text as input; this gives it the ability to describe the humor in unusual images, summarize text from screenshots, and answer exam questions that contain diagrams. It can now interact with users through spoken words and respond to images, allowing for more natural conversations and the ability to provide suggestions or answers based on photo uploads.\\nTo gain further control over GPT-4, OpenAI introduced the \"system message\", a directive in natural language given to GPT-4 in order to specify its tone of voice and task. For example, the system message can instruct the model to \"be a Shakespearean pirate\", in which case it will respond in rhyming, Shakespearean prose, or request it to \"always write the output of [its] response in JSON\", in which case the model will do so, adding keys and values as it sees fit to match the structure of its reply. In the examples provided by OpenAI, GPT-4 refused to deviate from its system message despite requests to do otherwise by the user during the conversation.\\nWhen instructed to do so, GPT-4 can interact with external interfaces. For example, the model could be instructed to enclose a query within <search></search> tags to perform a web search, the result of which would be inserted into the model\\'s prompt to allow it to form a response. This allows the model to perform tasks beyond its normal text-prediction capabilities, such as using APIs, generating images, and accessing and summarizing webpages.\\nA 2023 article in Nature stated programmers have found GPT-4 useful for assisting in coding tasks (despite its propensity for error), such as finding errors in existing'),\n",
       " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Huawei_PanGu', 'summary': \"Huawei PanGu, PanGu, PanGu-Σ or PanGu-π (Chinese: 盘古大模型; pinyin: pángǔ dà móxíng) is a multimodal large language model developed by Huawei. It was announced on July 7, 2023, positioned as a contender to other multimodal large language models.\\nThe name of the large learning language model, PanGu, was derived from the Chinese mythology and folklore of Pangu, a primordial character related to the creation of the world.\\n\\nIn April 2023, Huawei released a paper detailing the development of PanGu-Σ, a colossal language model featuring 1.085 trillion parameters. Developed within Huawei's MindSpore 5 framework, PanGu-Σ underwent training for over 100 days on a cluster system equipped with 512 Ascend 910 AI accelerator chips, processing 329 billion tokens in more than 40 natural and programming languages.\\nPanGu-Σ incorporates Random Routed Experts (RRE) and the Transformer decoder architecture, allowing easy extraction of sub-models for various applications like conversation, translation, code production, and natural language interpretation. The model achieves 6.3 times faster training throughput compared to MoE models with the same hyper-parameters. In the Chinese domain, it outperforms previous state-of-the-art models across 16 tasks in a zero-shot setting. Trained on datasets from 40 domains, including Chinese, English, Bilingual, and code, PanGu-Σ excels in few-shot natural-language understanding, open-domain discussion, question answering, machine translation, and code creation.\\n\\nDuring the Huawei Developer Conference on July 7, 2023, Huawei introduced PanGu 3.0, a large language model (LLM), tailored for sectors like government, finance, manufacturing, mining, and meteorology utilizing Huawei Cloud solutions. In the subsequent month, Huawei launched the Celia Virtual Assistant with advanced AI features, capable of generating long text replies based on user voice commands and set to release with HarmonyOS 4.0 for eligible devices.\\nThe LLM was designed for enterprises seeking advantages in the AI industry, focusing on task execution over creative work, unlike traditional models used for general purposes like chatbots, poetry, and visual content creation.\\nUsing the same technology as ChatGPT, Huawei's LLM features a hierarchical architecture, allowing customers to adapt the model to various tasks and train it on their own datasets, making it versatile across various industries.\\n\\nOn August 5, 2023, Huawei partnered with European Centre for Medium-Range Weather Forecasts (ECMWF) to launch a global weather forecasting AI model. This model used Huawei Cloud solutions and the PanGu-Weather Model with MindSpore. It is accessible on the ECMWF website and aims to provide accurate weather data.\\nOn December 19, 2023, Huawei announced its financial services on the PanGu-powered AI Finance platform for the global market. The tech giant introduced this product at the 2023 Huawei Cloud Fintech Summit, aiming to reshape the digital finance industry with efficient features to boost Fintech firms worldwide. The platform incorporated a variety of advanced technologies, including AI, big data analytics, and blockchain.\\nOn June 21, 2024 at HDC 2024, Huawei announced upgraded PanGu 5.0 alongside HarmonyOS NEXT. This version integrated with Harmony Intelligence, which features a smarter Celia (Xiaoyi) and focuses on generative AI updates to its LLM platform for creating new content, such as text, code, or images. Aiming to make PanGu accessible to a wide range of developers and businesses, it offered scalable options: smaller models requiring less computational power for those with limited resources, and larger models with increased capacities for complex tasks requiring more processing power.\\n\\nPanGu Large Model 3.0, designed for industry use, was structured with a 5+N+X three-tier architecture.\\n\\nFirst Layer (L0): Comprises PanGu's five basic large models to provide a variety of capabilities for different industry scenarios. These include Natural Language Processing (NLP) models, Visual models, Multimodal models, Prediction models, and Scientific Computing models.\\nSecond Layer (L1): Consists of N large industry-specific models. These models are trained using public data from various industries, such as government, finance, manufacturing, mining, and weather. Additionally, it uses customers' own data from L0 and L1 to train proprietary models tailored for each customer.\\nThird Layer (L2): Provides customers with detailed scenario-specific models. This layer focuses on specific applications or business needs, offering ready-to-use model services.\\nThe updated Huawei PanGu Model 5.0 by Huawei Cloud business division offered three key features: adaptability for different business scenarios, multi-style modeling, and advanced intelligence. Huawei divided the AI model platform into four series, each with different parameter scales:\\n\\nPanGu E Series: The Embedded version supports smart apps on phones, tablets, PCs, and other devices, with a parameter scale of 1 billion.\\nPanGu P Series: The Professional version features a 10-billion parameter scale, ideal for low-latency and low-cost reasoning conditions.\\nPanGu U Series: The Ultra version comes in two variants, with 135 billion and 230 billion parameters, capable of handling complex tasks and serving as a base for large models.\\nPanGu S Series: The Super PanGu is the top-tier edition, featuring trillion-level parameters, designed to manage advanced AI technology scenarios such as cross-domain or multi-tasking applications.\\n\\nLarge Language Model\\nGemini\\nGPT-4\", 'title': 'Huawei PanGu'}, page_content=\"Huawei PanGu, PanGu, PanGu-Σ or PanGu-π (Chinese: 盘古大模型; pinyin: pángǔ dà móxíng) is a multimodal large language model developed by Huawei. It was announced on July 7, 2023, positioned as a contender to other multimodal large language models.\\nThe name of the large learning language model, PanGu, was derived from the Chinese mythology and folklore of Pangu, a primordial character related to the creation of the world.\\n\\nIn April 2023, Huawei released a paper detailing the development of PanGu-Σ, a colossal language model featuring 1.085 trillion parameters. Developed within Huawei's MindSpore 5 framework, PanGu-Σ underwent training for over 100 days on a cluster system equipped with 512 Ascend 910 AI accelerator chips, processing 329 billion tokens in more than 40 natural and programming languages.\\nPanGu-Σ incorporates Random Routed Experts (RRE) and the Transformer decoder architecture, allowing easy extraction of sub-models for various applications like conversation, translation, code production, and natural language interpretation. The model achieves 6.3 times faster training throughput compared to MoE models with the same hyper-parameters. In the Chinese domain, it outperforms previous state-of-the-art models across 16 tasks in a zero-shot setting. Trained on datasets from 40 domains, including Chinese, English, Bilingual, and code, PanGu-Σ excels in few-shot natural-language understanding, open-domain discussion, question answering, machine translation, and code creation.\\n\\nDuring the Huawei Developer Conference on July 7, 2023, Huawei introduced PanGu 3.0, a large language model (LLM), tailored for sectors like government, finance, manufacturing, mining, and meteorology utilizing Huawei Cloud solutions. In the subsequent month, Huawei launched the Celia Virtual Assistant with advanced AI features, capable of generating long text replies based on user voice commands and set to release with HarmonyOS 4.0 for eligible devices.\\nThe LLM was designed for enterprises seeking advantages in the AI industry, focusing on task execution over creative work, unlike traditional models used for general purposes like chatbots, poetry, and visual content creation.\\nUsing the same technology as ChatGPT, Huawei's LLM features a hierarchical architecture, allowing customers to adapt the model to various tasks and train it on their own datasets, making it versatile across various industries.\\n\\nOn August 5, 2023, Huawei partnered with European Centre for Medium-Range Weather Forecasts (ECMWF) to launch a global weather forecasting AI model. This model used Huawei Cloud solutions and the PanGu-Weather Model with MindSpore. It is accessible on the ECMWF website and aims to provide accurate weather data.\\nOn December 19, 2023, Huawei announced its financial services on the PanGu-powered AI Finance platform for the global market. The tech giant introduced this product at the 2023 Huawei Cloud Fintech Summit, aiming to reshape the digital finance industry with efficient features to boost Fintech firms worldwide. The platform incorporated a variety of advanced technologies, including AI, big data analytics, and blockchain.\\nOn June 21, 2024 at HDC 2024, Huawei announced upgraded PanGu 5.0 alongside HarmonyOS NEXT. This version integrated with Harmony Intelligence, which features a smarter Celia (Xiaoyi) and focuses on generative AI updates to its LLM platform for creating new content, such as text, code, or images. Aiming to make PanGu accessible to a wide range of developers and businesses, it offered scalable options: smaller models requiring less computational power for those with limited resources, and larger models with increased capacities for complex tasks requiring more processing power.\\n\\nPanGu Large Model 3.0, designed for industry use, was structured with a 5+N+X three-tier architecture.\\n\\nFirst Layer (L0): Comprises PanGu's five basic large models to provide a variety of capabilities for different industry scenarios. These include Natural Language\")]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the retriever with a query\n",
    "doc = retriever.invoke(\"Google Gemini\")\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8486a26e-842a-444d-b81b-95752d3effce",
   "metadata": {},
   "source": [
    "## Task 5. Setup Model and Build LangChain `Chain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "249a0e90-3c0f-4a2b-bb90-c147b5d8b1fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Insert the correct model name in the constructor below.\n",
    "# https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-models\n",
    "# Ensure that the output is the least random configurable\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0.8, top_p=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c464dc6a-5b4c-49f2-88ae-7e0eb014d1ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] template=\"You are an assistant for question-answering tasks.\\nUse the following context to answer the question.\\nIf you don't know the answer, just say that you don't know.\\nUse five sentences maximum and keep the answer concise.\\n\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"\n"
     ]
    }
   ],
   "source": [
    "# Prompt template to query Gemini\n",
    "llm_prompt_template = \"\"\"You are an assistant for question-answering tasks.\n",
    "Use the following context to answer the question.\n",
    "If you don't know the answer, just say that you don't know.\n",
    "Use five sentences maximum and keep the answer concise.\\n\n",
    "Question: {question} \\nContext: {context} \\nAnswer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(llm_prompt_template)\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4676768-3023-498e-a21c-1f9a66aaa898",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c891317-71ea-4f71-9aaa-64134472e494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Complete the Chain in the correct order. You need to leverage the `prompt` and `model` defined\n",
    "# in earlier cells in the correct order to run the next cell successfully by replacing CHAIN_1 and CHAIN_2.\n",
    "chain = (\n",
    "    { \"context\": retriever | format_docs, \"question\": RunnablePassthrough() }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2173f89-1417-4259-a9d6-eeb85e739fdb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Gemini is a family of multimodal large language models developed by Google DeepMind. It serves as the successor to LaMDA and PaLM 2 and competes with OpenAI's GPT-4. Gemini comprises Ultra, Pro, Flash, and Nano, each designed for different computational tasks. Announced on December 6, 2023, Gemini powers Google's chatbot of the same name and will be integrated into other Google products like Search, Ads, and Android. \\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What is Gemini?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00824526-7a1f-470d-b02d-871f960e472a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-16.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-16:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
